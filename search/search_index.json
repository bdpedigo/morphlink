{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"examples/microns_example/","title":"Microns example","text":"<p>Note: while these packages are not required for the use of MorphLink, they are used here to demonstrate the functionality of the package with real data and integration with multiple other packages. This tutorial requires:</p> <ul> <li><code>CAVEclient</code>,</li> <li><code>skeletor</code>,</li> <li><code>pcg_skel</code>,</li> <li><code>pyvista</code>,</li> </ul> <p>all of which are available on PyPI.</p> <pre><code>from caveclient import CAVEclient\n\nclient = CAVEclient(\"minnie65_public\")\n</code></pre> <p>Create a <code>MorphLink</code> instance. This is the object we'll use for keeping track of different features and representations of morphology.</p> <pre><code>from morphlink import MorphLink\n\nmorphology = MorphLink()\n</code></pre> <p>We'll start by getting the morphology of a single neuron as a mesh.</p> <pre><code>root_id = 864691135361314119\n\ncv = client.info.segmentation_cloudvolume(progress=False)\nmesh = cv.mesh.get(\n    root_id, deduplicate_chunk_boundaries=False, remove_duplicate_vertices=False\n)[root_id]\n</code></pre> <p>We can add this to our morphology representation using the <code>add_mesh</code> method.</p> <pre><code>morphology.add_mesh(mesh, \"mesh\")\nmorphology.layers\n</code></pre> layer layer_type name mesh Mesh(vertices=(2652062, 3), faces=(5293626, 3)) Mesh <p>Next, we can add the nucleus location for this neuron. This is a new type of layer, in this case just a single point.</p> <pre><code>nuc_info = client.materialize.query_table(\n    \"nucleus_detection_v0\",\n    filter_equal_dict={\"pt_root_id\": root_id},\n    split_positions=True,\n    desired_resolution=[1, 1, 1],\n)\nnuc_loc = nuc_info[[\"pt_position_x\", \"pt_position_y\", \"pt_position_z\"]].values.squeeze()\nnuc_loc\n</code></pre> <pre>\n<code>array([725760., 491456., 853080.])</code>\n</pre> <pre><code>morphology.add_points(nuc_loc, \"nucleus\")\n</code></pre> <pre><code>morphology.layers\n</code></pre> layer layer_type name mesh Mesh(vertices=(2652062, 3), faces=(5293626, 3)) Mesh nucleus Points(points=(1, 3)) Points <pre><code>polydatas = morphology.to_pyvista()\n\nimport pyvista as pv\n\ndef set_camera(plotter, zoom=10):\n    plotter.camera.focal_point = nuc_loc\n    plotter.camera_position = \"zy\"\n    plotter.camera.up = (0, -1, 0)\n    plotter.camera.focal_point = nuc_loc\n    plotter.camera.zoom(zoom)\n\nWINDOW_SIZE = [2400, 1500]\npv.set_jupyter_backend(\"static\")\nplotter = pv.Plotter(window_size=WINDOW_SIZE)\nplotter.add_mesh(polydatas[\"mesh\"], color=\"lightgrey\", opacity=0.5)\nplotter.add_points(\n    polydatas[\"nucleus\"], color=\"red\", point_size=60, render_points_as_spheres=True\n)\n\nset_camera(plotter, zoom=5)\n\nplotter.show()\n</code></pre> <p>Similarly, we can add another layer that consists of many points - in this case, synapses onto this neuron.</p> <pre><code>post_synapses = client.materialize.query_table(\n    \"synapses_pni_2\",\n    filter_equal_dict={\"post_pt_root_id\": root_id},\n    split_positions=True,\n    desired_resolution=[1, 1, 1],\n)\npost_synapses.set_index(\"id\", inplace=True)\n</code></pre> <p>By setting the <code>spatial_columns</code> argument, we can specify which columns in the DataFrame correspond to spatial coordinates. This allows future methods to do space-aware operations on this layer. In the example above for the nucleus, the spatial columns were inferred since we passed in a 3-dimensional array.</p> <pre><code>morphology.add_points(\n    post_synapses,\n    \"post_synapses\",\n    spatial_columns=[\"ctr_pt_position_x\", \"ctr_pt_position_y\", \"ctr_pt_position_z\"],\n)\n</code></pre> <p>Now, let's link some of these objects together. The simplest mapping is to annotate the nucleus location on the mesh. Under the hood, the <code>add_link</code> method will find the closest point on the mesh and save that mapping.</p> <pre><code>morphology.add_link(\"nucleus\", \"mesh\")\n\nmorphology.links\n</code></pre> link source target nucleus mesh nucleus     mesh 0        0  1220064 <pre><code>plotter = pv.Plotter(window_size=WINDOW_SIZE)\nplotter.add_mesh(polydatas[\"mesh\"], color=\"lightgrey\")\nplotter.add_points(\n    morphology.post_synapses.to_pyvista(),\n    color=\"blue\",\n    point_size=10,\n    render_points_as_spheres=True,\n)\n\nset_camera(plotter, zoom=5)\n\nplotter.show()\n</code></pre> <p>Again, we can do this for synapses as well, here again finding the closest point on the mesh for each synapse.</p> <pre><code>morphology.add_link(\"post_synapses\", \"mesh\")\n\nmorphology.links\n</code></pre> link source target nucleus mesh nucleus     mesh 0        0  1220064 post_synapses mesh post_synapses     mesh 0         1873158... <p>We can retreive the mapping between the nucleus and the mesh using the <code>get_link</code> method. This returns a DataFrame with the mapping as its two columns.</p> <pre><code>morphology.get_link(\"nucleus\", \"mesh\")\n</code></pre> nucleus mesh 0 0 1220064 <p>We can also ask for the specific mapping for a point in our nucleus layer. Since we only have one point in this layer, we just get one item back from the mapping, denoting the closest point on the mesh.</p> <pre><code>mesh_nuc_index = morphology.get_mapping(\"nucleus\", \"mesh\")\n\nmesh_nuc_index\n</code></pre> <pre>\n<code>Index([1220064], dtype='int64', name='mesh')</code>\n</pre> <p>Now, we can do something a bit more interesting. Let's skeletonize the mesh, using the nucleus as the source points for the skeletonization.</p> <p>Note: requires <code>skeletor</code> package to be installed.</p> <pre><code>import time\n\nfrom skeletor.skeletonize import by_wavefront\n\ncurrtime = time.time()\n\nout = by_wavefront(mesh, origins=mesh_nuc_index.to_list(), progress=True)\nprint(f\"{time.time() - currtime:.3f} seconds elapsed.\")\n</code></pre> <pre>\n<code>Skeletonizing:   0%|          | 0/2652062 [00:00&lt;?, ?it/s]</code>\n</pre> <pre>\n<code>25.553 seconds elapsed.\n</code>\n</pre> <p>This skeletonization process stores the mapping between mesh vertices and the new, collapsed vertices from the skeletonization. First, let's add the skeleton to our morphology representations.</p> <pre><code>morphology.add_graph(out, \"skeleton\")\n</code></pre> <pre><code>plotter = pv.Plotter(window_size=WINDOW_SIZE)\nplotter.add_mesh(morphology.mesh.to_pyvista(), color=\"lightgrey\", opacity=0.3)\nplotter.add_mesh(\n    morphology.post_synapses.to_pyvista(),\n    color=\"blue\",\n    point_size=10,\n    render_points_as_spheres=True,\n)\nplotter.add_mesh(morphology.skeleton.to_pyvista(), color=\"red\", line_width=2)\nset_camera(plotter, zoom=5)\nplotter.show()\n</code></pre> <p>Then, we can add the mapping between the mesh and the skeleton. This mapping is stored in the <code>mesh_map</code> attribute of the skeletonization output.</p> <pre><code>morphology.add_link(\"mesh\", \"skeleton\", mapping=out.mesh_map)\n</code></pre> <pre><code>morphology.links\n</code></pre> link source target nucleus mesh nucleus     mesh 0        0  1220064 post_synapses mesh post_synapses     mesh 0         1873158... mesh skeleton mesh  skeleton 0              0   ... <p>Now, we might also be interested in where synapses are located along the skeleton. Even though the skeletonization map doesn't have a direct mapping between the mesh and the synapses, we can first map synapses to their points on the mesh, and then map those mesh points to their points on the skeleton.</p> <p>Fortunately, this kind of transitive mapping is handled automatically by MorphLink under the hood. Internally, there is a graph that denotes relationships between different layers, and the <code>link_path</code> method can be used to find the path from a source layer to a target layer (if one exists).</p> <p>Many times, this will just be a direct link.</p> <pre><code>morphology.get_link_path(\"post_synapses\", \"mesh\")\n</code></pre> <pre>\n<code>['post_synapses', 'mesh']</code>\n</pre> <p>But as in the case of the synapses and the skeleton, it will find the path that involves mapping synapses to the mesh, and then the mesh to the skeleton.</p> <pre><code>morphology.get_link_path(\"post_synapses\", \"skeleton\")\n</code></pre> <pre>\n<code>['post_synapses', 'mesh', 'skeleton']</code>\n</pre> <pre><code>synapse_skeleton_ids = morphology.get_mapping(\"post_synapses\", \"skeleton\")\nsynapse_skeleton_ids\n</code></pre> <pre>\n<code>Index([124839,  64175, 121215, 115029,  54276,  10115,  46720, 114390, 103022,\n        53731,\n       ...\n       133495,  97907,  48629,  27888,  46546, 116864,  71817,  67137, 116624,\n       116485],\n      dtype='int64', name='skeleton', length=3216)</code>\n</pre> <pre><code>skeleton_synapse_points = morphology.skeleton.nodes.iloc[synapse_skeleton_ids]\n\nplotter = pv.Plotter(window_size=WINDOW_SIZE)\nplotter.add_mesh(morphology.skeleton.to_pyvista(), color=\"red\", line_width=2)\nplotter.add_points(\n    skeleton_synapse_points.values,\n    color=\"blue\",\n    point_size=5,\n    render_points_as_spheres=True,\n)\nset_camera(plotter, zoom=5)\nplotter.show()\n</code></pre> <pre><code>import numpy as np\n\nedgelist = client.chunkedgraph.level2_chunk_graph(root_id)\nedgelist = np.array(edgelist)\n</code></pre> <pre><code>level2_ids = np.unique(edgelist)\n\nl2_data = client.l2cache.get_l2data(\n    level2_ids,\n    attributes=[\"area_nm2\", \"max_dt_nm\", \"mean_dt_nm\", \"size_nm3\", \"rep_coord_nm\"],\n)\n</code></pre> <pre><code>import pandas as pd\n\nl2_nodes = pd.DataFrame(l2_data).T\nl2_nodes.index = l2_nodes.index.astype(int)\nl2_nodes[\"x\"] = l2_nodes[\"rep_coord_nm\"].apply(lambda x: x[0])\nl2_nodes[\"y\"] = l2_nodes[\"rep_coord_nm\"].apply(lambda x: x[1])\nl2_nodes[\"z\"] = l2_nodes[\"rep_coord_nm\"].apply(lambda x: x[2])\n</code></pre> <pre><code>morphology.add_graph((l2_nodes, edgelist), \"l2_graph\", spatial_columns=[\"x\", \"y\", \"z\"])\nmorphology.layers\n</code></pre> layer layer_type name mesh Mesh(vertices=(2652062, 3), faces=(5293626, 3)) Mesh nucleus Points(points=(1, 3)) Points post_synapses Points(points=(3216, 3)) Points skeleton Graph(nodes=(155446, 3), edges=(154842, 2)) Graph l2_graph Graph(nodes=(11131, 8), edges=(12473, 2)) Graph <p>Skeletonizing the level2 graph can also provide a quick way to get a skeleton, albeit at the loss of some spatial resolution.</p> <pre><code>from pcg_skel import pcg_skeleton_direct\n</code></pre> <pre><code>morphology.l2_graph.vertices\n</code></pre> <pre>\n<code>array([[485504., 623368., 862520.],\n       [484488., 623928., 861720.],\n       [487552., 619264., 863640.],\n       ...,\n       [968952., 670280., 862800.],\n       [968976., 671688., 862520.],\n       [969088., 672544., 862600.]])</code>\n</pre> <p>Note that the edges were supplied as named index pairs, not on positional node indices.</p> <pre><code>morphology.l2_graph.edges\n</code></pre> <pre>\n<code>array([[153486945027096730, 153487013746573379],\n       [153486945027096730, 153557313771274442],\n       [153487013746573379, 153557382490751099],\n       ...,\n       [170095617920467521, 170165986664644757],\n       [170165917945168013, 170165986664644757],\n       [170165986664644757, 170166055384121514]])</code>\n</pre> <p>But <code>edges_positional</code> will return the edges with positional node indices.</p> <pre><code>morphology.l2_graph.edges_positional\n</code></pre> <pre>\n<code>array([[    0,     1],\n       [    0,     4],\n       [    1,     5],\n       ...,\n       [11127, 11129],\n       [11128, 11129],\n       [11129, 11130]])</code>\n</pre> <pre><code>pcg_skeleton = pcg_skeleton_direct(\n    morphology.l2_graph.vertices,\n    morphology.l2_graph.edges_positional,\n    collapse_soma=True,\n    root_point=np.squeeze(morphology.nucleus.vertices),\n)\n</code></pre> <pre>\n<code>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 11130/11130 [00:00&lt;00:00, 55457.28it/s]\n</code>\n</pre> <pre><code>morphology.add_graph(pcg_skeleton, \"pcg_skeleton\")\n</code></pre> <pre><code>plotter = pv.Plotter(window_size=WINDOW_SIZE)\n# pv.set_jupyter_backend('client')\n# plotter = pv.Plotter()\nplotter.add_mesh(morphology.mesh.to_pyvista(), color=\"lightgrey\", opacity=0.3)\nplotter.add_mesh(morphology.l2_graph.to_pyvista(), color=\"lime\", line_width=3)\nplotter.add_mesh(morphology.pcg_skeleton.to_pyvista(), color=\"darkred\", line_width=3)\n\nset_camera(plotter, zoom=15)\n\nplotter.show()\n</code></pre> <p>Again, let's add some links, including the one created by the skeletonization process. The rest will just be again based on nearest point mappings, for now.</p> <pre><code>morphology.add_link(\"l2_graph\", \"pcg_skeleton\", mapping=pcg_skeleton.mesh_to_skel_map)\nmorphology.add_link(\"nucleus\", \"pcg_skeleton\", mapping=\"closest\")\n\n# these ones in particular are not perfect and could be refined with CAVEclient calls,\n# but let's see how it does\nmorphology.add_link(\"mesh\", \"pcg_skeleton\", mapping=\"closest\")\nmorphology.add_link(\"l2_graph\", \"mesh\", mapping=\"closest\")\n</code></pre> <pre><code>morphology.links\n</code></pre> link source target nucleus mesh nucleus     mesh 0        0  1220064 post_synapses mesh post_synapses     mesh 0         1873158... mesh skeleton mesh  skeleton 0              0   ... l2_graph pcg_skeleton l2_graph  pcg_skeleton 0     ... nucleus pcg_skeleton nucleus  pcg_skeleton 0        0          5535 mesh pcg_skeleton mesh  pcg_skeleton 0              ... l2_graph mesh l2_graph     mesh 0      1534... <p>A common operation one might want to do on a neuron is to mask out the axon, or extract just the axon, etc. <code>morphlink</code> aims to be agnostic to how you want to compute something like \"where is the axon on this neuron\", and is only here to help you keep track of how that labeling implicitly applies to other parts of a morphology.</p> <p>As a concrete example, computing this kind of split of axon/dendrite can be done using the skeleton and its synapses.</p> <pre><code>pre_synapses = client.materialize.query_table(\n    \"synapses_pni_2\",\n    filter_equal_dict={\"pre_pt_root_id\": root_id},\n    split_positions=True,\n    desired_resolution=[1, 1, 1],\n)\npre_synapses = pre_synapses.query(\"pre_pt_root_id != post_pt_root_id\")\npre_synapses.set_index(\"id\", inplace=True)\n\nmorphology.add_points(\n    pre_synapses,\n    \"pre_synapses\",\n    spatial_columns=[\"ctr_pt_position_x\", \"ctr_pt_position_y\", \"ctr_pt_position_z\"],\n)\n</code></pre> <pre><code>morphology.add_link(\"pre_synapses\", \"mesh\")\n</code></pre> <pre><code>morphology.links\n</code></pre> link source target nucleus mesh nucleus     mesh 0        0  1220064 post_synapses mesh post_synapses     mesh 0         1873158... mesh skeleton mesh  skeleton 0              0   ... l2_graph pcg_skeleton l2_graph  pcg_skeleton 0     ... nucleus pcg_skeleton nucleus  pcg_skeleton 0        0          5535 mesh pcg_skeleton mesh  pcg_skeleton 0              ... l2_graph mesh l2_graph     mesh 0      1534... pre_synapses mesh pre_synapses     mesh 0       221097100  ... <pre><code>morphology.get_mapping(\"post_synapses\", \"pcg_skeleton\")\n</code></pre> <pre>\n<code>Index([4277, 5535, 4105, 4047, 1973,  501, 1654, 3932, 3586, 1904,\n       ...\n       4559, 3299, 1752, 1073, 1664, 4041, 2532, 2292, 4093, 4034],\n      dtype='int64', name='pcg_skeleton', length=3216)</code>\n</pre> <pre><code>morphology.get_mapping(\"pre_synapses\", \"pcg_skeleton\")\n</code></pre> <pre>\n<code>Index([5216, 3623, 2283,  377, 1480, 5475,  421, 4343, 5395, 4625,\n       ...\n        578, 4340, 1179,  553, 3149, 4246,  103, 4228, 4341, 4789],\n      dtype='int64', name='pcg_skeleton', length=657)</code>\n</pre> <pre><code>from scipy.sparse.linalg import eigsh\nfrom scipy.sparse import diags_array\n\nadj = morphology.pcg_skeleton.to_adjacency()\nadj = adj + adj.T\ndegrees = adj.sum(axis=0)\ndegree_matrix = diags_array([degrees], offsets=[0], shape=adj.shape)\nlaplacian = degree_matrix - adj\n\neigvals, eigvecs = eigsh(laplacian, k=5, sigma=-1e-12)\n</code></pre> <pre><code>post_inds = morphology.get_mapping(\"post_synapses\", \"pcg_skeleton\")\npre_inds = morphology.get_mapping(\"pre_synapses\", \"pcg_skeleton\")\n\nX_post = eigvecs[post_inds]\nX_pre = eigvecs[pre_inds]\n\ny_post = np.zeros(len(post_inds))\ny_pre = np.ones(len(pre_inds))\n\nX = np.concatenate([X_post, X_pre])\ny = np.concatenate([y_post, y_pre])\n\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n\ncols = np.arange(1, eigvecs.shape[1])\nlda = LinearDiscriminantAnalysis()\nlda.fit(X[:, cols], y)\n\npred_labels = lda.predict(eigvecs[:, cols])\n</code></pre> <pre><code>morphology.pcg_skeleton.nodes[\"pred_label\"] = pred_labels\n</code></pre> <pre><code>plotter = pv.Plotter(window_size=WINDOW_SIZE)\nplotter.add_mesh(morphology.mesh.to_pyvista(), color=\"lightgrey\", opacity=0.3)\nplotter.add_mesh(\n    morphology.pcg_skeleton.to_pyvista(),\n    color=\"darkred\",\n    scalars=pred_labels,\n    cmap=\"coolwarm\",\n    line_width=3,\n    show_scalar_bar=False,\n)\nplotter.add_points(\n    morphology.post_synapses.to_pyvista(),\n    color=\"blue\",\n    point_size=5,\n    render_points_as_spheres=True,\n)\nplotter.add_points(\n    morphology.pre_synapses.to_pyvista(),\n    color=\"red\",\n    point_size=5,\n    render_points_as_spheres=True,\n)\nset_camera(plotter, zoom=4)\nplotter.show()\n</code></pre> <p>Now, the more interesting part: independent of whatever algorithm we chose for doing this split for us, let's see how to mask the rest of the neuron based on this split.</p> <p>First, let's see what masking the skeleton by the predicted axon label we just added will look like.</p> <pre><code>masked_skeleton = morphology.pcg_skeleton.query_nodes(\"pred_label == 0\")\n</code></pre> <pre><code>plotter = pv.Plotter(window_size=WINDOW_SIZE)\nplotter.add_mesh(morphology.mesh.to_pyvista(), color=\"lightgrey\", opacity=0.3)\nplotter.add_mesh(\n    morphology.pcg_skeleton.to_pyvista(),\n    color=\"lightgrey\",\n    line_width=2,\n    show_scalar_bar=False,\n)\nplotter.add_mesh(masked_skeleton.to_pyvista(), color=\"black\", line_width=8)\nset_camera(plotter, zoom=4)\nplotter.show()\n</code></pre> <p>Notice that the parts in light grey above are gone in the filtered skeleton. Unfortunately, this masking didn't keep track of implicit filtering that happened to the other layers when masking this layer on its own. This is where <code>morphlink</code> comes in handy: it can keep track of these implicit mappings for you.</p> <p>This time, we'll use <code>query_nodes</code> but on the <code>morphology</code> object itself, and now we will also specify the layer we are talking about.</p> <pre><code>morphology.drop_layer(\"skeleton\")  # dropping because no path to pcg_skeleton\nmasked_morphology = morphology.query_nodes(\"pred_label == 0\", \"pcg_skeleton\")\nmasked_morphology\n</code></pre> <pre>\n<code>MorphLink(layers=['mesh', 'nucleus', 'post_synapses', 'l2_graph', 'pcg_skeleton', 'pre_synapses'], links=[], tables=[])</code>\n</pre> <pre><code>plotter = pv.Plotter(window_size=WINDOW_SIZE, shape=(1, 2))\n\nplotter.subplot(0, 0)\nplotter.add_mesh(morphology.mesh.to_pyvista(), color=\"lightgrey\", opacity=0.3)\nplotter.add_mesh(\n    morphology.pcg_skeleton.to_pyvista(),\n    scalars=morphology.pcg_skeleton.nodes[\"pred_label\"],\n    cmap=\"coolwarm\",\n    line_width=2,\n    show_scalar_bar=False,\n)\nplotter.add_points(\n    morphology.pre_synapses.to_pyvista(),\n    color=\"red\",\n    point_size=5,\n    render_points_as_spheres=True,\n)\nplotter.add_points(\n    morphology.post_synapses.to_pyvista(),\n    color=\"blue\",\n    point_size=5,\n    render_points_as_spheres=True,\n)\n\nplotter.subplot(0, 1)\nplotter.add_mesh(masked_morphology.mesh.to_pyvista(), color=\"lightgrey\", opacity=0.3)\nplotter.add_mesh(\n    masked_morphology.pcg_skeleton.to_pyvista(),\n    scalars=masked_morphology.pcg_skeleton.nodes[\"pred_label\"],\n    cmap=\"coolwarm\",\n    line_width=2,\n    show_scalar_bar=False,\n)\nplotter.add_points(\n    masked_morphology.pre_synapses.to_pyvista(),\n    color=\"red\",\n    point_size=5,\n    render_points_as_spheres=True,\n)\nplotter.add_points(\n    masked_morphology.post_synapses.to_pyvista(),\n    color=\"blue\",\n    point_size=5,\n    render_points_as_spheres=True,\n)\n\nplotter.link_views()\nset_camera(plotter, zoom=2)\nplotter.show()\n</code></pre> <p>As a sanity check, note that now very few presynaptic sites are left in our morphology,  as expected since we masked out the axon.</p> <pre><code>masked_morphology.pre_synapses.nodes.shape[0]\n</code></pre> <pre>\n<code>10</code>\n</pre>"},{"location":"examples/microns_example/#initialization","title":"Initialization","text":"<p>Start a CAVEclient</p>"},{"location":"examples/microns_example/#adding-a-mesh","title":"Adding a mesh","text":""},{"location":"examples/microns_example/#adding-point-annotations","title":"Adding point annotations","text":""},{"location":"examples/microns_example/#adding-a-skeleton","title":"Adding a skeleton","text":""},{"location":"examples/microns_example/#more-complex-mappings","title":"More complex mappings","text":""},{"location":"examples/microns_example/#working-with-a-level2-graph","title":"Working with a level2 graph","text":""},{"location":"examples/microns_example/#masking-and-filtering","title":"Masking and filtering","text":""}]}